{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd920a3-9666-44d7-86cf-9a6bdde83518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,SimpleRNN\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05368d1c-8af5-4bc7-8914-8d87b1f78c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Demand</th>\n",
       "      <th>Net_Generation</th>\n",
       "      <th>Total_Interchange</th>\n",
       "      <th>Forecasted_Demand</th>\n",
       "      <th>Coal_Gen</th>\n",
       "      <th>Gas_Gen</th>\n",
       "      <th>Nuclear_Gen</th>\n",
       "      <th>Hydro_Gen</th>\n",
       "      <th>...</th>\n",
       "      <th>Season_Summer</th>\n",
       "      <th>Season_Winter</th>\n",
       "      <th>Demand_Prev_Hour</th>\n",
       "      <th>Demand_Yesterday_Same_Hour</th>\n",
       "      <th>Demand_Last_Week_Same_Hour</th>\n",
       "      <th>Rolling_Mean_3H</th>\n",
       "      <th>Rolling_Mean_24H</th>\n",
       "      <th>Total_Gen</th>\n",
       "      <th>Renewable_Pct</th>\n",
       "      <th>Fossil_Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-01 17:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>28976.042</td>\n",
       "      <td>21138.304</td>\n",
       "      <td>-6528.677</td>\n",
       "      <td>28386.220</td>\n",
       "      <td>8.764</td>\n",
       "      <td>7725.951</td>\n",
       "      <td>2261.073</td>\n",
       "      <td>3089.741</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31560.368</td>\n",
       "      <td>97906.322</td>\n",
       "      <td>30623.583</td>\n",
       "      <td>52909.261</td>\n",
       "      <td>42604.509</td>\n",
       "      <td>17521.203</td>\n",
       "      <td>42.950</td>\n",
       "      <td>44.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-01 18:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>29065.500</td>\n",
       "      <td>21217.885</td>\n",
       "      <td>-6554.521</td>\n",
       "      <td>28486.010</td>\n",
       "      <td>8.792</td>\n",
       "      <td>7761.917</td>\n",
       "      <td>2261.062</td>\n",
       "      <td>3110.594</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19035.781</td>\n",
       "      <td>36973.722</td>\n",
       "      <td>30187.366</td>\n",
       "      <td>26585.677</td>\n",
       "      <td>41847.195</td>\n",
       "      <td>17577.073</td>\n",
       "      <td>42.927</td>\n",
       "      <td>44.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-01 19:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>29154.958</td>\n",
       "      <td>21297.467</td>\n",
       "      <td>-6580.365</td>\n",
       "      <td>28585.800</td>\n",
       "      <td>8.819</td>\n",
       "      <td>7797.882</td>\n",
       "      <td>2261.052</td>\n",
       "      <td>3131.446</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120405.354</td>\n",
       "      <td>28886.583</td>\n",
       "      <td>96196.009</td>\n",
       "      <td>60325.969</td>\n",
       "      <td>45629.697</td>\n",
       "      <td>17632.943</td>\n",
       "      <td>42.904</td>\n",
       "      <td>44.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-01 20:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>29244.417</td>\n",
       "      <td>21377.049</td>\n",
       "      <td>-6606.208</td>\n",
       "      <td>28685.590</td>\n",
       "      <td>8.847</td>\n",
       "      <td>7833.847</td>\n",
       "      <td>2261.042</td>\n",
       "      <td>3152.299</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8629.271</td>\n",
       "      <td>31655.750</td>\n",
       "      <td>35642.181</td>\n",
       "      <td>23684.576</td>\n",
       "      <td>48609.446</td>\n",
       "      <td>17688.812</td>\n",
       "      <td>42.881</td>\n",
       "      <td>44.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-01 21:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>29333.875</td>\n",
       "      <td>21456.630</td>\n",
       "      <td>-6632.052</td>\n",
       "      <td>28785.380</td>\n",
       "      <td>8.875</td>\n",
       "      <td>7869.812</td>\n",
       "      <td>2261.031</td>\n",
       "      <td>3173.151</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31562.326</td>\n",
       "      <td>29065.500</td>\n",
       "      <td>8211.854</td>\n",
       "      <td>30046.873</td>\n",
       "      <td>49142.567</td>\n",
       "      <td>17744.682</td>\n",
       "      <td>42.858</td>\n",
       "      <td>44.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525055</th>\n",
       "      <td>2023-06-29 20:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>64967.778</td>\n",
       "      <td>65025.979</td>\n",
       "      <td>58.042</td>\n",
       "      <td>65732.083</td>\n",
       "      <td>8989.486</td>\n",
       "      <td>27552.910</td>\n",
       "      <td>4647.181</td>\n",
       "      <td>32.896</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40554.444</td>\n",
       "      <td>14324.708</td>\n",
       "      <td>37711.542</td>\n",
       "      <td>67747.671</td>\n",
       "      <td>49409.849</td>\n",
       "      <td>46077.069</td>\n",
       "      <td>10.607</td>\n",
       "      <td>79.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525056</th>\n",
       "      <td>2023-06-29 21:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>64902.135</td>\n",
       "      <td>64963.474</td>\n",
       "      <td>61.177</td>\n",
       "      <td>65699.302</td>\n",
       "      <td>8993.729</td>\n",
       "      <td>27593.401</td>\n",
       "      <td>4647.292</td>\n",
       "      <td>33.224</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31739.526</td>\n",
       "      <td>22046.601</td>\n",
       "      <td>65821.128</td>\n",
       "      <td>37511.137</td>\n",
       "      <td>46137.266</td>\n",
       "      <td>46106.208</td>\n",
       "      <td>10.566</td>\n",
       "      <td>79.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525057</th>\n",
       "      <td>2023-06-29 22:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>64836.493</td>\n",
       "      <td>64900.969</td>\n",
       "      <td>64.312</td>\n",
       "      <td>65666.521</td>\n",
       "      <td>8997.972</td>\n",
       "      <td>27633.892</td>\n",
       "      <td>4647.403</td>\n",
       "      <td>33.552</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15892.381</td>\n",
       "      <td>31801.521</td>\n",
       "      <td>21450.109</td>\n",
       "      <td>39168.139</td>\n",
       "      <td>45454.091</td>\n",
       "      <td>46135.347</td>\n",
       "      <td>10.526</td>\n",
       "      <td>79.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525058</th>\n",
       "      <td>2023-06-29 23:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>64770.851</td>\n",
       "      <td>64838.464</td>\n",
       "      <td>67.448</td>\n",
       "      <td>65633.740</td>\n",
       "      <td>9002.215</td>\n",
       "      <td>27674.384</td>\n",
       "      <td>4647.514</td>\n",
       "      <td>33.880</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22263.507</td>\n",
       "      <td>97828.229</td>\n",
       "      <td>41419.396</td>\n",
       "      <td>42477.179</td>\n",
       "      <td>39779.804</td>\n",
       "      <td>46164.486</td>\n",
       "      <td>10.485</td>\n",
       "      <td>79.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525059</th>\n",
       "      <td>2023-06-30 00:00:00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>64705.208</td>\n",
       "      <td>64775.958</td>\n",
       "      <td>70.583</td>\n",
       "      <td>65600.958</td>\n",
       "      <td>9006.458</td>\n",
       "      <td>27714.875</td>\n",
       "      <td>4647.625</td>\n",
       "      <td>34.208</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14294.583</td>\n",
       "      <td>40397.181</td>\n",
       "      <td>15884.782</td>\n",
       "      <td>36136.653</td>\n",
       "      <td>44508.672</td>\n",
       "      <td>46193.625</td>\n",
       "      <td>10.444</td>\n",
       "      <td>79.494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525060 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  Hour     Demand  Net_Generation  \\\n",
       "0       2018-07-01 17:00:00  12.5  28976.042       21138.304   \n",
       "1       2018-07-01 18:00:00  12.5  29065.500       21217.885   \n",
       "2       2018-07-01 19:00:00  12.5  29154.958       21297.467   \n",
       "3       2018-07-01 20:00:00  12.5  29244.417       21377.049   \n",
       "4       2018-07-01 21:00:00  12.5  29333.875       21456.630   \n",
       "...                     ...   ...        ...             ...   \n",
       "525055  2023-06-29 20:00:00  12.5  64967.778       65025.979   \n",
       "525056  2023-06-29 21:00:00  12.5  64902.135       64963.474   \n",
       "525057  2023-06-29 22:00:00  12.5  64836.493       64900.969   \n",
       "525058  2023-06-29 23:00:00  12.5  64770.851       64838.464   \n",
       "525059  2023-06-30 00:00:00  12.5  64705.208       64775.958   \n",
       "\n",
       "        Total_Interchange  Forecasted_Demand  Coal_Gen    Gas_Gen  \\\n",
       "0               -6528.677          28386.220     8.764   7725.951   \n",
       "1               -6554.521          28486.010     8.792   7761.917   \n",
       "2               -6580.365          28585.800     8.819   7797.882   \n",
       "3               -6606.208          28685.590     8.847   7833.847   \n",
       "4               -6632.052          28785.380     8.875   7869.812   \n",
       "...                   ...                ...       ...        ...   \n",
       "525055             58.042          65732.083  8989.486  27552.910   \n",
       "525056             61.177          65699.302  8993.729  27593.401   \n",
       "525057             64.312          65666.521  8997.972  27633.892   \n",
       "525058             67.448          65633.740  9002.215  27674.384   \n",
       "525059             70.583          65600.958  9006.458  27714.875   \n",
       "\n",
       "        Nuclear_Gen  Hydro_Gen  ...  Season_Summer  Season_Winter  \\\n",
       "0          2261.073   3089.741  ...              1              0   \n",
       "1          2261.062   3110.594  ...              1              0   \n",
       "2          2261.052   3131.446  ...              1              0   \n",
       "3          2261.042   3152.299  ...              1              0   \n",
       "4          2261.031   3173.151  ...              1              0   \n",
       "...             ...        ...  ...            ...            ...   \n",
       "525055     4647.181     32.896  ...              1              0   \n",
       "525056     4647.292     33.224  ...              1              0   \n",
       "525057     4647.403     33.552  ...              1              0   \n",
       "525058     4647.514     33.880  ...              1              0   \n",
       "525059     4647.625     34.208  ...              1              0   \n",
       "\n",
       "        Demand_Prev_Hour  Demand_Yesterday_Same_Hour  \\\n",
       "0              31560.368                   97906.322   \n",
       "1              19035.781                   36973.722   \n",
       "2             120405.354                   28886.583   \n",
       "3               8629.271                   31655.750   \n",
       "4              31562.326                   29065.500   \n",
       "...                  ...                         ...   \n",
       "525055         40554.444                   14324.708   \n",
       "525056         31739.526                   22046.601   \n",
       "525057         15892.381                   31801.521   \n",
       "525058         22263.507                   97828.229   \n",
       "525059         14294.583                   40397.181   \n",
       "\n",
       "        Demand_Last_Week_Same_Hour  Rolling_Mean_3H  Rolling_Mean_24H  \\\n",
       "0                        30623.583        52909.261         42604.509   \n",
       "1                        30187.366        26585.677         41847.195   \n",
       "2                        96196.009        60325.969         45629.697   \n",
       "3                        35642.181        23684.576         48609.446   \n",
       "4                         8211.854        30046.873         49142.567   \n",
       "...                            ...              ...               ...   \n",
       "525055                   37711.542        67747.671         49409.849   \n",
       "525056                   65821.128        37511.137         46137.266   \n",
       "525057                   21450.109        39168.139         45454.091   \n",
       "525058                   41419.396        42477.179         39779.804   \n",
       "525059                   15884.782        36136.653         44508.672   \n",
       "\n",
       "        Total_Gen  Renewable_Pct  Fossil_Pct  \n",
       "0       17521.203         42.950      44.145  \n",
       "1       17577.073         42.927      44.209  \n",
       "2       17632.943         42.904      44.273  \n",
       "3       17688.812         42.881      44.337  \n",
       "4       17744.682         42.858      44.400  \n",
       "...           ...            ...         ...  \n",
       "525055  46077.069         10.607      79.307  \n",
       "525056  46106.208         10.566      79.354  \n",
       "525057  46135.347         10.526      79.401  \n",
       "525058  46164.486         10.485      79.448  \n",
       "525059  46193.625         10.444      79.494  \n",
       "\n",
       "[525060 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\rosem\\Downloads\\FINAL_PROJECT_WORKS\\CSV_files\\featue_engg_data1.csv\")\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9b0735-c46f-4fcc-a557-ed8e7108b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Processing region: California\n",
      "California - Demand RMSE: 2494.99, MAE: 1605.10, MAPE: 4.97%\n",
      "California - COâ‚‚ RMSE: 1113.51, MAE: 827.21, MAPE: 15.90%\n",
      "\n",
      "ðŸ“Š Processing region: Texas\n",
      "Texas - Demand RMSE: 4875.72, MAE: 3659.13, MAPE: 7.15%\n",
      "Texas - COâ‚‚ RMSE: 3209.02, MAE: 2422.79, MAPE: 17.84%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_forecast(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mae, mape\n",
    "\n",
    "# --------------------------\n",
    "# Function for each region\n",
    "# --------------------------\n",
    "def rbm_forecasting(region_code, display_name):\n",
    "    print(f\"\\nðŸ“Š Processing region: {display_name}\")\n",
    "\n",
    "    # Filter the data\n",
    "    region_df = df[df['Region'] == region_code].copy()\n",
    "    region_df['Date'] = pd.to_datetime(region_df['Date'])\n",
    "    region_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Daily aggregation\n",
    "    daily_data = region_df.groupby(region_df.index).agg({\n",
    "        'Demand': 'sum',\n",
    "        'CO2_Total_Emissions': 'sum',\n",
    "        'Hour': 'mean',\n",
    "        'Month': 'mean',\n",
    "        'DayOfWeek': 'mean',\n",
    "        'Is_Weekend': 'mean',\n",
    "        'DayOfYear': 'mean',\n",
    "        'WeekOfYear': 'mean',\n",
    "        'Season_Autumn': 'mean',\n",
    "        'Season_Spring': 'mean',\n",
    "        'Season_Summer': 'mean',\n",
    "        'Season_Winter': 'mean',\n",
    "        'Renewable_Pct': 'mean',\n",
    "        'Fossil_Pct': 'mean',\n",
    "        'Demand_Prev_Hour': 'mean',\n",
    "        'Demand_Yesterday_Same_Hour': 'mean',\n",
    "        'Demand_Last_Week_Same_Hour': 'mean',\n",
    "        'Rolling_Mean_3H': 'mean',\n",
    "        'Rolling_Mean_24H': 'mean'\n",
    "    })\n",
    "\n",
    "    features = daily_data[[\n",
    "        'Hour', 'Month', 'DayOfWeek', 'Is_Weekend', 'DayOfYear', 'WeekOfYear',\n",
    "        'Season_Autumn', 'Season_Spring', 'Season_Summer', 'Season_Winter',\n",
    "        'Renewable_Pct', 'Fossil_Pct',\n",
    "        'Demand_Prev_Hour', 'Demand_Yesterday_Same_Hour', 'Demand_Last_Week_Same_Hour',\n",
    "        'Rolling_Mean_3H', 'Rolling_Mean_24H'\n",
    "    ]]\n",
    "    targets = daily_data[['Demand', 'CO2_Total_Emissions']]\n",
    "\n",
    "    # Scaling\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(features)\n",
    "    y_scaled = scaler_y.fit_transform(targets)\n",
    "\n",
    "    # Train/Test split\n",
    "    split = int(0.8 * len(X_scaled))\n",
    "    X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
    "    y_train, y_test = y_scaled[:split], y_scaled[split:]\n",
    "    test_dates = daily_data.index[split:]\n",
    "\n",
    "    # Define RBM + NN pipeline\n",
    "    rbm_nn = Pipeline(steps=[\n",
    "        ('rbm', BernoulliRBM(n_components=64, learning_rate=0.06, n_iter=10, random_state=42)),\n",
    "        ('mlp', MLPRegressor(hidden_layer_sizes=(128, 64), activation='relu', max_iter=500, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    rbm_nn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_scaled = rbm_nn.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    # ----------------------\n",
    "    # Evaluation Metrics\n",
    "    # ----------------------\n",
    "    rmse_demand, mae_demand, mape_demand = evaluate_forecast(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_co2, mae_co2, mape_co2 = evaluate_forecast(y_true[:, 1], y_pred[:, 1])\n",
    "\n",
    "    print(f\"{display_name} - Demand RMSE: {rmse_demand:.2f}, MAE: {mae_demand:.2f}, MAPE: {mape_demand:.2f}%\")\n",
    "    print(f\"{display_name} - COâ‚‚ RMSE: {rmse_co2:.2f}, MAE: {mae_co2:.2f}, MAPE: {mape_co2:.2f}%\")\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Date': test_dates,\n",
    "        'Region': display_name,\n",
    "        'Actual_Demand': y_true[:, 0],\n",
    "        'Predicted_Demand': y_pred[:, 0],\n",
    "        'Actual_CO2': y_true[:, 1],\n",
    "        'Predicted_CO2': y_pred[:, 1]\n",
    "    })\n",
    "   # result_df.to_csv(f\"rbm_nn_forecast_{region_code.lower()}.csv\", index=False)\n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        'Region': display_name,\n",
    "        'Demand': {'RMSE': rmse_demand, 'MAE': mae_demand, 'MAPE': mape_demand},\n",
    "        'CO2': {'RMSE': rmse_co2, 'MAE': mae_co2, 'MAPE': mape_co2}\n",
    "    }\n",
    "\n",
    "# âœ… Run for both California and Texas\n",
    "cal_metrics = rbm_forecasting(\"CAL\", \"California\")\n",
    "tex_metrics = rbm_forecasting(\"TEX\", \"Texas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baed6267-46a7-467a-88e8-3d37721c58f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Processing region: California\n",
      "California - Demand RMSE: 2334.83, MAE: 1570.84, MAPE: 4.95%\n",
      "California - COâ‚‚ RMSE: 1117.26, MAE: 827.58, MAPE: 15.77%\n",
      "\n",
      "ðŸ“Š Processing region: Texas\n",
      "Texas - Demand RMSE: 7479.84, MAE: 6280.16, MAPE: 12.15%\n",
      "Texas - COâ‚‚ RMSE: 2696.38, MAE: 2052.47, MAPE: 13.92%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_forecast(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mae, mape\n",
    "\n",
    "# --------------------------\n",
    "# Function for each region\n",
    "# --------------------------\n",
    "def rbm_forecasting(region_code, display_name):\n",
    "    print(f\"\\nðŸ“Š Processing region: {display_name}\")\n",
    "\n",
    "    # Filter the data\n",
    "    region_df = df[df['Region'] == region_code].copy()\n",
    "    region_df['Date'] = pd.to_datetime(region_df['Date'])\n",
    "    region_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Daily aggregation\n",
    "    daily_data = region_df.groupby(region_df.index).agg({\n",
    "        'Demand': 'sum',\n",
    "        'CO2_Total_Emissions': 'sum',\n",
    "        'Hour': 'mean',\n",
    "        'Month': 'mean',\n",
    "        'DayOfWeek': 'mean',\n",
    "        'Is_Weekend': 'mean',\n",
    "        'DayOfYear': 'mean',\n",
    "        'WeekOfYear': 'mean',\n",
    "        'Season_Autumn': 'mean',\n",
    "        'Season_Spring': 'mean',\n",
    "        'Season_Summer': 'mean',\n",
    "        'Season_Winter': 'mean',\n",
    "        'Renewable_Pct': 'mean',\n",
    "        'Fossil_Pct': 'mean',\n",
    "        'Demand_Prev_Hour': 'mean',\n",
    "        'Demand_Yesterday_Same_Hour': 'mean',\n",
    "        'Demand_Last_Week_Same_Hour': 'mean',\n",
    "        'Rolling_Mean_3H': 'mean',\n",
    "        'Rolling_Mean_24H': 'mean'\n",
    "    })\n",
    "\n",
    "    features = daily_data[[\n",
    "        'Hour', 'Month', 'DayOfWeek', 'Is_Weekend', 'DayOfYear', 'WeekOfYear',\n",
    "        'Season_Autumn', 'Season_Spring', 'Season_Summer', 'Season_Winter',\n",
    "        'Renewable_Pct', 'Fossil_Pct',\n",
    "        'Demand_Prev_Hour', 'Demand_Yesterday_Same_Hour', 'Demand_Last_Week_Same_Hour',\n",
    "        'Rolling_Mean_3H', 'Rolling_Mean_24H'\n",
    "    ]]\n",
    "    targets = daily_data[['Demand', 'CO2_Total_Emissions']]\n",
    "\n",
    "    # Scaling\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(features)\n",
    "    y_scaled = scaler_y.fit_transform(targets)\n",
    "\n",
    "    # Train/Test split\n",
    "    split = int(0.75 * len(X_scaled))\n",
    "    X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
    "    y_train, y_test = y_scaled[:split], y_scaled[split:]\n",
    "    test_dates = daily_data.index[split:]\n",
    "\n",
    "    # Define RBM + NN pipeline\n",
    "    rbm_nn = Pipeline(steps=[\n",
    "        ('rbm', BernoulliRBM(n_components=64, learning_rate=0.06, n_iter=10, random_state=42)),\n",
    "        ('mlp', MLPRegressor(hidden_layer_sizes=(128, 64), activation='relu', max_iter=500, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    rbm_nn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_scaled = rbm_nn.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    # ----------------------\n",
    "    # Evaluation Metrics\n",
    "    # ----------------------\n",
    "    rmse_demand, mae_demand, mape_demand = evaluate_forecast(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_co2, mae_co2, mape_co2 = evaluate_forecast(y_true[:, 1], y_pred[:, 1])\n",
    "\n",
    "    print(f\"{display_name} - Demand RMSE: {rmse_demand:.2f}, MAE: {mae_demand:.2f}, MAPE: {mape_demand:.2f}%\")\n",
    "    print(f\"{display_name} - COâ‚‚ RMSE: {rmse_co2:.2f}, MAE: {mae_co2:.2f}, MAPE: {mape_co2:.2f}%\")\n",
    "\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Date': test_dates,\n",
    "        'Region': display_name,\n",
    "        'Actual_Demand': y_true[:, 0],\n",
    "        'Predicted_Demand': y_pred[:, 0],\n",
    "        'Actual_CO2': y_true[:, 1],\n",
    "        'Predicted_CO2': y_pred[:, 1]\n",
    "    })\n",
    "   # result_df.to_csv(f\"rbm_nn_forecast_{region_code.lower()}.csv\", index=False)\n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        'Region': display_name,\n",
    "        'Demand': {'RMSE': rmse_demand, 'MAE': mae_demand, 'MAPE': mape_demand},\n",
    "        'CO2': {'RMSE': rmse_co2, 'MAE': mae_co2, 'MAPE': mape_co2}\n",
    "    }\n",
    "\n",
    "# âœ… Run for both California and Texas\n",
    "cal_metrics = rbm_forecasting(\"CAL\", \"California\")\n",
    "tex_metrics = rbm_forecasting(\"TEX\", \"Texas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd12a9a3-8711-4b9c-a44f-08b4ed6a8af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Processing region: California\n",
      "California - Demand RMSE: 2487.90, MAE: 1689.90, MAPE: 5.33%\n",
      "California - COâ‚‚ RMSE: 1080.12, MAE: 804.41, MAPE: 16.76%\n",
      "\n",
      "ðŸ“Š Processing region: Texas\n",
      "Texas - Demand RMSE: 7132.35, MAE: 5936.98, MAPE: 11.69%\n",
      "Texas - COâ‚‚ RMSE: 2465.81, MAE: 1855.79, MAPE: 12.13%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_forecast(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mae, mape\n",
    "\n",
    "# --------------------------\n",
    "# Function for each region\n",
    "# --------------------------\n",
    "def rbm_forecasting(region_code, display_name):\n",
    "    print(f\"\\nðŸ“Š Processing region: {display_name}\")\n",
    "\n",
    "    # Filter the data\n",
    "    region_df = df[df['Region'] == region_code].copy()\n",
    "    region_df['Date'] = pd.to_datetime(region_df['Date'])\n",
    "    region_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Daily aggregation\n",
    "    daily_data = region_df.groupby(region_df.index).agg({\n",
    "        'Demand': 'sum',\n",
    "        'CO2_Total_Emissions': 'sum',\n",
    "        'Hour': 'mean',\n",
    "        'Month': 'mean',\n",
    "        'DayOfWeek': 'mean',\n",
    "        'Is_Weekend': 'mean',\n",
    "        'DayOfYear': 'mean',\n",
    "        'WeekOfYear': 'mean',\n",
    "        'Season_Autumn': 'mean',\n",
    "        'Season_Spring': 'mean',\n",
    "        'Season_Summer': 'mean',\n",
    "        'Season_Winter': 'mean',\n",
    "        'Renewable_Pct': 'mean',\n",
    "        'Fossil_Pct': 'mean',\n",
    "        'Demand_Prev_Hour': 'mean',\n",
    "        'Demand_Yesterday_Same_Hour': 'mean',\n",
    "        'Demand_Last_Week_Same_Hour': 'mean',\n",
    "        'Rolling_Mean_3H': 'mean',\n",
    "        'Rolling_Mean_24H': 'mean'\n",
    "    })\n",
    "\n",
    "    features = daily_data[[\n",
    "        'Hour', 'Month', 'DayOfWeek', 'Is_Weekend', 'DayOfYear', 'WeekOfYear',\n",
    "        'Season_Autumn', 'Season_Spring', 'Season_Summer', 'Season_Winter',\n",
    "        'Renewable_Pct', 'Fossil_Pct',\n",
    "        'Demand_Prev_Hour', 'Demand_Yesterday_Same_Hour', 'Demand_Last_Week_Same_Hour',\n",
    "        'Rolling_Mean_3H', 'Rolling_Mean_24H'\n",
    "    ]]\n",
    "    targets = daily_data[['Demand', 'CO2_Total_Emissions']]\n",
    "\n",
    "    # Scaling\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(features)\n",
    "    y_scaled = scaler_y.fit_transform(targets)\n",
    "\n",
    "    # Train/Test split\n",
    "    split = int(0.7 * len(X_scaled))\n",
    "    X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
    "    y_train, y_test = y_scaled[:split], y_scaled[split:]\n",
    "    test_dates = daily_data.index[split:]\n",
    "\n",
    "    # Define RBM + NN pipeline\n",
    "    rbm_nn = Pipeline(steps=[\n",
    "        ('rbm', BernoulliRBM(n_components=64, learning_rate=0.06, n_iter=10, random_state=42)),\n",
    "        ('mlp', MLPRegressor(hidden_layer_sizes=(128, 64), activation='relu', max_iter=500, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    rbm_nn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_scaled = rbm_nn.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    # ----------------------\n",
    "    # Evaluation Metrics\n",
    "    # ----------------------\n",
    "    rmse_demand, mae_demand, mape_demand = evaluate_forecast(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_co2, mae_co2, mape_co2 = evaluate_forecast(y_true[:, 1], y_pred[:, 1])\n",
    "\n",
    "    print(f\"{display_name} - Demand RMSE: {rmse_demand:.2f}, MAE: {mae_demand:.2f}, MAPE: {mape_demand:.2f}%\")\n",
    "    print(f\"{display_name} - COâ‚‚ RMSE: {rmse_co2:.2f}, MAE: {mae_co2:.2f}, MAPE: {mape_co2:.2f}%\")\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Date': test_dates,\n",
    "        'Region': display_name,\n",
    "        'Actual_Demand': y_true[:, 0],\n",
    "        'Predicted_Demand': y_pred[:, 0],\n",
    "        'Actual_CO2': y_true[:, 1],\n",
    "        'Predicted_CO2': y_pred[:, 1]\n",
    "    })\n",
    "   # result_df.to_csv(f\"rbm_nn_forecast_{region_code.lower()}.csv\", index=False)\n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        'Region': display_name,\n",
    "        'Demand': {'RMSE': rmse_demand, 'MAE': mae_demand, 'MAPE': mape_demand},\n",
    "        'CO2': {'RMSE': rmse_co2, 'MAE': mae_co2, 'MAPE': mape_co2}\n",
    "    }\n",
    "\n",
    "# âœ… Run for both California and Texas\n",
    "cal_metrics = rbm_forecasting(\"CAL\", \"California\")\n",
    "tex_metrics = rbm_forecasting(\"TEX\", \"Texas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ab0998-e61b-4374-b6e6-b5ee4ffa0178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Processing region: California\n",
      "California - Demand RMSE: 2533.00, MAE: 1715.42, MAPE: 5.53%\n",
      "California - COâ‚‚ RMSE: 1077.85, MAE: 805.30, MAPE: 17.01%\n",
      "\n",
      "ðŸ“Š Processing region: Texas\n",
      "Texas - Demand RMSE: 6525.97, MAE: 5422.93, MAPE: 10.93%\n",
      "Texas - COâ‚‚ RMSE: 2284.96, MAE: 1741.58, MAPE: 11.27%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_forecast(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mae, mape\n",
    "\n",
    "# --------------------------\n",
    "# Function for each region\n",
    "# --------------------------\n",
    "def rbm_forecasting(region_code, display_name):\n",
    "    print(f\"\\nðŸ“Š Processing region: {display_name}\")\n",
    "\n",
    "    # Filter the data\n",
    "    region_df = df[df['Region'] == region_code].copy()\n",
    "    region_df['Date'] = pd.to_datetime(region_df['Date'])\n",
    "    region_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Daily aggregation\n",
    "    daily_data = region_df.groupby(region_df.index).agg({\n",
    "        'Demand': 'sum',\n",
    "        'CO2_Total_Emissions': 'sum',\n",
    "        'Hour': 'mean',\n",
    "        'Month': 'mean',\n",
    "        'DayOfWeek': 'mean',\n",
    "        'Is_Weekend': 'mean',\n",
    "        'DayOfYear': 'mean',\n",
    "        'WeekOfYear': 'mean',\n",
    "        'Season_Autumn': 'mean',\n",
    "        'Season_Spring': 'mean',\n",
    "        'Season_Summer': 'mean',\n",
    "        'Season_Winter': 'mean',\n",
    "        'Renewable_Pct': 'mean',\n",
    "        'Fossil_Pct': 'mean',\n",
    "        'Demand_Prev_Hour': 'mean',\n",
    "        'Demand_Yesterday_Same_Hour': 'mean',\n",
    "        'Demand_Last_Week_Same_Hour': 'mean',\n",
    "        'Rolling_Mean_3H': 'mean',\n",
    "        'Rolling_Mean_24H': 'mean'\n",
    "    })\n",
    "\n",
    "    features = daily_data[[\n",
    "        'Hour', 'Month', 'DayOfWeek', 'Is_Weekend', 'DayOfYear', 'WeekOfYear',\n",
    "        'Season_Autumn', 'Season_Spring', 'Season_Summer', 'Season_Winter',\n",
    "        'Renewable_Pct', 'Fossil_Pct',\n",
    "        'Demand_Prev_Hour', 'Demand_Yesterday_Same_Hour', 'Demand_Last_Week_Same_Hour',\n",
    "        'Rolling_Mean_3H', 'Rolling_Mean_24H'\n",
    "    ]]\n",
    "    targets = daily_data[['Demand', 'CO2_Total_Emissions']]\n",
    "\n",
    "    # Scaling\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(features)\n",
    "    y_scaled = scaler_y.fit_transform(targets)\n",
    "\n",
    "    # Train/Test split\n",
    "    split = int(0.65 * len(X_scaled))\n",
    "    X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
    "    y_train, y_test = y_scaled[:split], y_scaled[split:]\n",
    "    test_dates = daily_data.index[split:]\n",
    "\n",
    "    # Define RBM + NN pipeline\n",
    "    rbm_nn = Pipeline(steps=[\n",
    "        ('rbm', BernoulliRBM(n_components=64, learning_rate=0.06, n_iter=10, random_state=42)),\n",
    "        ('mlp', MLPRegressor(hidden_layer_sizes=(128, 64), activation='relu', max_iter=500, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    rbm_nn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_scaled = rbm_nn.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    # ----------------------\n",
    "    # Evaluation Metrics\n",
    "    # ----------------------\n",
    "    rmse_demand, mae_demand, mape_demand = evaluate_forecast(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_co2, mae_co2, mape_co2 = evaluate_forecast(y_true[:, 1], y_pred[:, 1])\n",
    "\n",
    "    print(f\"{display_name} - Demand RMSE: {rmse_demand:.2f}, MAE: {mae_demand:.2f}, MAPE: {mape_demand:.2f}%\")\n",
    "    print(f\"{display_name} - COâ‚‚ RMSE: {rmse_co2:.2f}, MAE: {mae_co2:.2f}, MAPE: {mape_co2:.2f}%\")\n",
    "\n",
    "    # ----------------------\n",
    "    # Plotting\n",
    "    # ----------------------\n",
    "    # plt.figure(figsize=(14, 5))\n",
    "    # plt.plot(test_dates, y_true[:, 0], label='Actual Demand')\n",
    "    # plt.plot(test_dates, y_pred[:, 0], label='Predicted Demand (RBM + NN)')\n",
    "    # plt.title(f\"{display_name} â€“ Electricity Demand Forecast (RBM + NN)\")\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure(figsize=(14, 5))\n",
    "    # plt.plot(test_dates, y_true[:, 1], label='Actual COâ‚‚ Emissions')\n",
    "    # plt.plot(test_dates, y_pred[:, 1], label='Predicted COâ‚‚ (RBM + NN)')\n",
    "    # plt.title(f\"{display_name} â€“ COâ‚‚ Emissions Forecast (RBM + NN)\")\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "\n",
    "    # Export Results to CSV\n",
    "    result_df = pd.DataFrame({\n",
    "        'Date': test_dates,\n",
    "        'Region': display_name,\n",
    "        'Actual_Demand': y_true[:, 0],\n",
    "        'Predicted_Demand': y_pred[:, 0],\n",
    "        'Actual_CO2': y_true[:, 1],\n",
    "        'Predicted_CO2': y_pred[:, 1]\n",
    "    })\n",
    "   # result_df.to_csv(f\"rbm_nn_forecast_{region_code.lower()}.csv\", index=False)\n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        'Region': display_name,\n",
    "        'Demand': {'RMSE': rmse_demand, 'MAE': mae_demand, 'MAPE': mape_demand},\n",
    "        'CO2': {'RMSE': rmse_co2, 'MAE': mae_co2, 'MAPE': mape_co2}\n",
    "    }\n",
    "\n",
    "# âœ… Run for both California and Texas\n",
    "cal_metrics = rbm_forecasting(\"CAL\", \"California\")\n",
    "tex_metrics = rbm_forecasting(\"TEX\", \"Texas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84dd597-c7f1-49e8-969e-91bd45d6671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Processing region: California\n",
      "California - Demand RMSE: 2388.70, MAE: 1645.90, MAPE: 5.18%\n",
      "California - COâ‚‚ RMSE: 1171.79, MAE: 882.22, MAPE: 17.49%\n",
      "\n",
      "ðŸ“Š Processing region: Texas\n",
      "Texas - Demand RMSE: 6022.78, MAE: 4705.56, MAPE: 9.28%\n",
      "Texas - COâ‚‚ RMSE: 2494.46, MAE: 1924.64, MAPE: 12.57%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_forecast(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mae, mape\n",
    "\n",
    "# --------------------------\n",
    "# Function for each region\n",
    "# --------------------------\n",
    "def rbm_forecasting(region_code, display_name):\n",
    "    print(f\"\\nðŸ“Š Processing region: {display_name}\")\n",
    "\n",
    "    # Filter the data\n",
    "    region_df = df[df['Region'] == region_code].copy()\n",
    "    region_df['Date'] = pd.to_datetime(region_df['Date'])\n",
    "    region_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Daily aggregation\n",
    "    daily_data = region_df.groupby(region_df.index).agg({\n",
    "        'Demand': 'sum',\n",
    "        'CO2_Total_Emissions': 'sum',\n",
    "        'Hour': 'mean',\n",
    "        'Month': 'mean',\n",
    "        'DayOfWeek': 'mean',\n",
    "        'Is_Weekend': 'mean',\n",
    "        'DayOfYear': 'mean',\n",
    "        'WeekOfYear': 'mean',\n",
    "        'Season_Autumn': 'mean',\n",
    "        'Season_Spring': 'mean',\n",
    "        'Season_Summer': 'mean',\n",
    "        'Season_Winter': 'mean',\n",
    "        'Renewable_Pct': 'mean',\n",
    "        'Fossil_Pct': 'mean',\n",
    "        'Demand_Prev_Hour': 'mean',\n",
    "        'Demand_Yesterday_Same_Hour': 'mean',\n",
    "        'Demand_Last_Week_Same_Hour': 'mean',\n",
    "        'Rolling_Mean_3H': 'mean',\n",
    "        'Rolling_Mean_24H': 'mean'\n",
    "    })\n",
    "\n",
    "    features = daily_data[[\n",
    "        'Hour', 'Month', 'DayOfWeek', 'Is_Weekend', 'DayOfYear', 'WeekOfYear',\n",
    "        'Season_Autumn', 'Season_Spring', 'Season_Summer', 'Season_Winter',\n",
    "        'Renewable_Pct', 'Fossil_Pct',\n",
    "        'Demand_Prev_Hour', 'Demand_Yesterday_Same_Hour', 'Demand_Last_Week_Same_Hour',\n",
    "        'Rolling_Mean_3H', 'Rolling_Mean_24H'\n",
    "    ]]\n",
    "    targets = daily_data[['Demand', 'CO2_Total_Emissions']]\n",
    "\n",
    "    # Scaling\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(features)\n",
    "    y_scaled = scaler_y.fit_transform(targets)\n",
    "\n",
    "    # Train/Test split\n",
    "    split = int(0.6 * len(X_scaled))\n",
    "    X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
    "    y_train, y_test = y_scaled[:split], y_scaled[split:]\n",
    "    test_dates = daily_data.index[split:]\n",
    "\n",
    "    # Define RBM + NN pipeline\n",
    "    rbm_nn = Pipeline(steps=[\n",
    "        ('rbm', BernoulliRBM(n_components=64, learning_rate=0.06, n_iter=10, random_state=42)),\n",
    "        ('mlp', MLPRegressor(hidden_layer_sizes=(128, 64), activation='relu', max_iter=500, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    rbm_nn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_scaled = rbm_nn.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    # ----------------------\n",
    "    # Evaluation Metrics\n",
    "    # ----------------------\n",
    "    rmse_demand, mae_demand, mape_demand = evaluate_forecast(y_true[:, 0], y_pred[:, 0])\n",
    "    rmse_co2, mae_co2, mape_co2 = evaluate_forecast(y_true[:, 1], y_pred[:, 1])\n",
    "\n",
    "    print(f\"{display_name} - Demand RMSE: {rmse_demand:.2f}, MAE: {mae_demand:.2f}, MAPE: {mape_demand:.2f}%\")\n",
    "    print(f\"{display_name} - COâ‚‚ RMSE: {rmse_co2:.2f}, MAE: {mae_co2:.2f}, MAPE: {mape_co2:.2f}%\")\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Date': test_dates,\n",
    "        'Region': display_name,\n",
    "        'Actual_Demand': y_true[:, 0],\n",
    "        'Predicted_Demand': y_pred[:, 0],\n",
    "        'Actual_CO2': y_true[:, 1],\n",
    "        'Predicted_CO2': y_pred[:, 1]\n",
    "    })\n",
    "   # result_df.to_csv(f\"rbm_nn_forecast_{region_code.lower()}.csv\", index=False)\n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        'Region': display_name,\n",
    "        'Demand': {'RMSE': rmse_demand, 'MAE': mae_demand, 'MAPE': mape_demand},\n",
    "        'CO2': {'RMSE': rmse_co2, 'MAE': mae_co2, 'MAPE': mape_co2}\n",
    "    }\n",
    "\n",
    "# âœ… Run for both California and Texas\n",
    "cal_metrics = rbm_forecasting(\"CAL\", \"California\")\n",
    "tex_metrics = rbm_forecasting(\"TEX\", \"Texas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e0265-1187-4979-9d29-1352c633dc14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
